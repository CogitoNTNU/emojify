{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sondre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sondre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "c:\\Users\\Sondre\\Documents\\kodegit\\emojify\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time\n",
    "import torch\n",
    "plt.rcParams['figure.figsize'] = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995  i just had a very brief time in the beanbag an...  sadness\n",
       "15996  i am now turning and i feel pathetic that i am...  sadness\n",
       "15997                     i feel strong and good overall      joy\n",
       "15998  i feel like this was such a rude comment and i...    anger\n",
       "15999  i know a lot but i feel so stupid because i ca...  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.txt', sep=\";\", names=['text', 'label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i just feel so fucked up these days\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "print(df.text[1599])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before removing stopwords: 15210\n",
      "Number of 'I': 25859\n",
      "Length after removing stopwords: 15062\n"
     ]
    }
   ],
   "source": [
    "#lage list of sentences\n",
    "list_of_sentences = []\n",
    "for i in range(len(df)):\n",
    "    list_of_sentences.append(df.text[i])\n",
    "\n",
    "#lage list of word\n",
    "list_of_word = []\n",
    "for i in range(len(list_of_sentences)):\n",
    "    list_of_word.extend(word_tokenize(list_of_sentences[i]))\n",
    "    \n",
    "\n",
    "#lage bag of words\n",
    "bag_of_words = {}\n",
    "for word in list_of_word:\n",
    "    if word in bag_of_words.keys():\n",
    "        bag_of_words[word] += 1\n",
    "    else:\n",
    "        bag_of_words[word] = 1\n",
    "\n",
    "\n",
    "\n",
    "#før fjerning\n",
    "print(\"Length before removing stopwords:\", len(bag_of_words.keys()))\n",
    "print(\"Number of 'I':\", bag_of_words['i'])\n",
    "\n",
    "#definere stopwords\n",
    "stop_words_english = set(stopwords.words('english'))\n",
    "bag_of_words_keys = list(bag_of_words.keys())\n",
    "\n",
    "\n",
    "#fjerne stopwords\n",
    "for i in bag_of_words_keys:\n",
    "    if i in stop_words_english:\n",
    "        bag_of_words.pop(i)\n",
    "        \n",
    "\n",
    "#sjekke om de er fjerna\n",
    "print(\"Length after removing stopwords:\", len(bag_of_words.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#få en liste fra keys\n",
    "def getList(dict):\n",
    "    list = []\n",
    "    for value in dict.values():\n",
    "        list.append(value)\n",
    "         \n",
    "    return list\n",
    "\n",
    "#lage bag of words som gir ut antall av hvert eneste ord til en enkelt setning\n",
    "def make_bag_of_words(counter, setning):\n",
    "    bag_of_word = {}\n",
    "    list_setning = word_tokenize(setning)\n",
    "    for word in bag_of_words.keys():\n",
    "        bag_of_word[word] = 0\n",
    "    \n",
    "    for word in bag_of_words.keys():\n",
    "        if word in list_setning:\n",
    "            for ord in list_setning:\n",
    "                if word == ord:\n",
    "                    bag_of_word[word] += 1\n",
    "        else:\n",
    "            bag_of_word[word] = 0\n",
    "    \n",
    "    list_bag_of_word = getList(bag_of_word)\n",
    "    list_bag_of_word.insert(0, counter)\n",
    "    return list_bag_of_word\n",
    "\n",
    "g = (make_bag_of_words(89, \"i i am feeling feeling grouchy\"))\n",
    "#print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16000/16000 [01:31<00:00, 174.43it/s]\n"
     ]
    }
   ],
   "source": [
    "#øverste rad er orda\n",
    "bow_matrise = []\n",
    "bow_matrise.append(getList(bag_of_words))\n",
    "\n",
    "#legge inn antall ordforekomst i hver setning\n",
    "iteration_counter = 1\n",
    "for setence in tqdm(list_of_sentences):\n",
    "    bow_matrise.append(make_bag_of_words(iteration_counter ,setence))\n",
    "    iteration_counter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word index: 0 , antall:  15936\n",
      "word index: 2 , antall:  1\n",
      "word index: 772 , antall:  1\n",
      "word index: 940 , antall:  1\n",
      "word index: 3338 , antall:  1\n",
      "im better than the rest of you feeling but a feeling of being accepted\n"
     ]
    }
   ],
   "source": [
    "#test for å se hvilkene ord setningene inneholder\n",
    "number = 15936\n",
    "\n",
    "liste = (bow_matrise[number])\n",
    "for tall in range(len(liste)):\n",
    "    if liste[tall] != 0:\n",
    "        print(\"word index:\", tall, \", antall: \", liste[tall])\n",
    "print (list_of_sentences[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funksjon for å fjerne øverste rad og første kolonne\n",
    "def fjern_f(matrise):\n",
    "    del matrise[0]\n",
    "    for i in range(len(matrise)):\n",
    "        del matrise[i][0]\n",
    "    return matrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15210/15210 [00:00<00:00, 3041060.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#values til ordlista:\n",
    "kolonner = fjern_f(bow_matrise)\n",
    "\n",
    "#keys til ordlista:\n",
    "kolonne_navn = bag_of_words_keys\n",
    "\n",
    "#ordlista med ord som keys: og tilhørende value som en liste med antall av hvert ord\n",
    "dict_til_def = {kolonne_navn[i]: kolonner[i] for i in tqdm(range(len(kolonne_navn)))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lage dataframe\n",
    "df_ai = pd.DataFrame(data=dict_til_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>didnt</th>\n",
       "      <th>feel</th>\n",
       "      <th>humiliated</th>\n",
       "      <th>can</th>\n",
       "      <th>go</th>\n",
       "      <th>from</th>\n",
       "      <th>feeling</th>\n",
       "      <th>so</th>\n",
       "      <th>hopeless</th>\n",
       "      <th>...</th>\n",
       "      <th>pandora</th>\n",
       "      <th>cosmopolitian</th>\n",
       "      <th>monkees</th>\n",
       "      <th>tearing</th>\n",
       "      <th>celebrities</th>\n",
       "      <th>irrelevant</th>\n",
       "      <th>braeden</th>\n",
       "      <th>calvin</th>\n",
       "      <th>beanbag</th>\n",
       "      <th>subbing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15057</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15058</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15060</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15061</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15062 rows × 15210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       i  didnt  feel  humiliated  can  go  from  feeling  so  hopeless  ...  \\\n",
       "0      1      0     0           0    0   0     0        0   0         0  ...   \n",
       "1      1      0     1           0    0   0     1        1   1         1  ...   \n",
       "2      1      0     0           0    0   0     0        0   0         0  ...   \n",
       "3      0      1     0           0    0   0     0        0   0         0  ...   \n",
       "4      0      1     0           1    1   1     0        0   0         0  ...   \n",
       "...   ..    ...   ...         ...  ...  ..   ...      ...  ..       ...  ...   \n",
       "15057  0      0     0           0    0   0     0        0   0         0  ...   \n",
       "15058  0      0     0           0    0   0     0        0   0         0  ...   \n",
       "15059  0      0     0           0    0   0     0        0   0         0  ...   \n",
       "15060  0      0     0           0    0   0     0        0   0         0  ...   \n",
       "15061  0      0     0           0    0   0     0        0   0         0  ...   \n",
       "\n",
       "       pandora  cosmopolitian  monkees  tearing  celebrities  irrelevant  \\\n",
       "0            0              0        0        0            0           0   \n",
       "1            0              0        0        1            0           1   \n",
       "2            0              0        0        0            0           0   \n",
       "3            0              0        0        0            0           0   \n",
       "4            0              1        1        0            0           0   \n",
       "...        ...            ...      ...      ...          ...         ...   \n",
       "15057        0              0        0        0            0           0   \n",
       "15058        0              0        0        0            0           0   \n",
       "15059        0              0        0        0            0           0   \n",
       "15060        0              0        0        0            0           0   \n",
       "15061        0              0        0        0            0           0   \n",
       "\n",
       "       braeden  calvin  beanbag  subbing  \n",
       "0            0       0        0        0  \n",
       "1            1       1        0        1  \n",
       "2            0       0        0        0  \n",
       "3            0       0        0        0  \n",
       "4            0       0        1        0  \n",
       "...        ...     ...      ...      ...  \n",
       "15057        0       0        0        0  \n",
       "15058        0       0        0        0  \n",
       "15059        0       0        0        0  \n",
       "15060        0       0        0        0  \n",
       "15061        0       0        0        0  \n",
       "\n",
       "[15062 rows x 15210 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sjekke den nye dataframen\n",
    "df_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feelings = df\n",
    "feelings.head()\n",
    "\n",
    "###alt under er hentet fra nettet\n",
    "\n",
    "X = feelings['text']\n",
    "Y = feelings['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#teste greia\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 12770)\n",
      "(4000, 12770)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "\n",
    "# fit and transform X_train\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Print shape of X_train_bow and X_test_bow\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nøyaktigheten til classifieren basert på dette settet er: 77.525 %\n",
      "Setning:  i am angry at you\n",
      "Passende følelse til denne setningen: anger\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Create a MultinomialNB object\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf.score(X_test_bow, y_test)\n",
    "print(\"Nøyaktigheten til classifieren basert på dette settet er:\", accuracy*100, \"%\")\n",
    "\n",
    "# Predict the feeling\n",
    "review = 'i am angry at you'\n",
    "print(\"Setning: \", review)\n",
    "prediction = clf.predict(vectorizer.transform([review]))[0]\n",
    "print(\"Passende følelse til denne setningen:\" , (prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b79e3d7d167d4069fb766c32f028f5953b64b8f9640b3f62e503fa38ff6e71a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
